{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import logging\n",
      "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
      "from gensim import corpora, models, similarities"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "documents = [\"Human machine interface for lab abc computer applications\",\n",
      "             \"A survey of user opinion of computer system response time\",\n",
      "             \"The EPS user interface management system\",\n",
      "             \"System and human system engineering testing of EPS\",\n",
      "             \"Relation of user perceived response time to error measurement\",\n",
      "             \"The generation of random binary unordered trees\",\n",
      "             \"The intersection graph of paths in trees\",\n",
      "             \"Graph minors IV Widths of trees and well quasi ordering\",\n",
      "             \"Graph minors A survey\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# remove common words and tokenize\n",
      "stoplist = set('for a of the and to in'.split())\n",
      "texts = [[word for word in document.lower().split() if word not in stoplist]\n",
      "         for document in documents]\n",
      "\n",
      "# remove words that appear only once\n",
      "all_tokens = sum(texts, [])\n",
      "tokens_once = set(word for word in set(all_tokens) if all_tokens.count(word) == 1)\n",
      "texts = [[word for word in text if word not in tokens_once]\n",
      "\t\t for text in texts]\n",
      "\n",
      "print(texts)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[['human', 'interface', 'computer'], ['survey', 'user', 'computer', 'system', 'response', 'time'], ['eps', 'user', 'interface', 'system'], ['system', 'human', 'system', 'eps'], ['user', 'response', 'time'], ['trees'], ['graph', 'trees'], ['graph', 'minors', 'trees'], ['graph', 'minors', 'survey']]\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dictionary = corpora.Dictionary(texts)\n",
      "dictionary.save('deerwester.dict')\n",
      "print(dictionary)\n",
      "print(dictionary.token2id)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Dictionary(12 unique tokens: [u'minors', u'graph', u'system', u'trees', u'eps']...)\n",
        "{u'minors': 11, u'graph': 10, u'system': 5, u'trees': 9, u'eps': 8, u'computer': 0, u'survey': 4, u'user': 7, u'human': 1, u'time': 6, u'interface': 2, u'response': 3}\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "new_doc = \"Human computer interaction\"\n",
      "new_vec = dictionary.doc2bow(new_doc.lower().split())\n",
      "print(new_vec)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(0, 1), (1, 1)]\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "corpus = [dictionary.doc2bow(text) for text in texts]\n",
      "corpora.MmCorpus.serialize('deerwester.mm', corpus)\n",
      "print(corpus)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[(0, 1), (1, 1), (2, 1)], [(0, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)], [(2, 1), (5, 1), (7, 1), (8, 1)], [(1, 1), (5, 2), (8, 1)], [(3, 1), (6, 1), (7, 1)], [(9, 1)], [(9, 1), (10, 1)], [(9, 1), (10, 1), (11, 1)], [(4, 1), (10, 1), (11, 1)]]\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class MyCorpus(object):\n",
      "    def __iter__(self):\n",
      "        for line in open('mycorpus.txt'):\n",
      "            # assume there's one document per line, tokens separated by whitespace\n",
      "            yield dictionary.doc2bow(line.lower().split())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "corpus_memory_friendly = MyCorpus()\n",
      "print(corpus_memory_friendly)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<__main__.MyCorpus object at 0x10d6e7050>\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Corpus is now an object. We didn\u2019t define any way to print it, so print just outputs address of the object in memory. \n",
      "# Not very useful. To see the constituent vectors, let\u2019s iterate over the corpus and print each document vector (one at a time):\n",
      "\n",
      "for vector in corpus_memory_friendly:\n",
      "    print(vector)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(0, 1), (1, 1), (2, 1)]\n",
        "[(0, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)]\n",
        "[(2, 1), (5, 1), (7, 1), (8, 1)]\n",
        "[(1, 1), (5, 2), (8, 1)]\n",
        "[(3, 1), (6, 1), (7, 1)]\n",
        "[(9, 1)]\n",
        "[(9, 1), (10, 1)]\n",
        "[(9, 1), (10, 1), (11, 1)]\n",
        "[(4, 1), (10, 1), (11, 1)]\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Similarly, to construct the dictionary without loading all texts into memory:\n",
      "\n",
      "# collect statistics about all tokens\n",
      "dictionary = corpora.Dictionary(line.lower().split() for line in open('mycorpus.txt'))\n",
      "# remove stop words and words that appear only once\n",
      "stop_ids = [dictionary.token2id[stopword] for stopword in stoplist\n",
      "            if stopword in dictionary.token2id]\n",
      "once_ids = [tokenid for tokenid, docfreq in dictionary.dfs.iteritems() if docfreq == 1]\n",
      "dictionary.filter_tokens(stop_ids + once_ids) # remove stop words and words that appear only once\n",
      "dictionary.compactify() # remove gaps in id sequence after words that were removed\n",
      "print(dictionary)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Dictionary(12 unique tokens: [u'minors', u'graph', u'system', u'trees', u'eps']...)\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Tutorial 2"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dictionary = corpora.Dictionary.load('deerwester.dict')\n",
      "corpus = corpora.MmCorpus('deerwester.mm')\n",
      "print(corpus)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "MmCorpus(9 documents, 12 features, 28 non-zero entries)\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tfidf = models.TfidfModel(corpus) # step 1 -- initialize a model"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "doc_bow = [(0, 1), (1, 1)]\n",
      "print(tfidf[doc_bow])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(0, 0.7071067811865476), (1, 0.7071067811865476)]\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "corpus_tfidf = tfidf[corpus]\n",
      "for doc in corpus_tfidf:\n",
      "    print(doc)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(0, 0.5773502691896257), (1, 0.5773502691896257), (2, 0.5773502691896257)]\n",
        "[(0, 0.44424552527467476), (3, 0.44424552527467476), (4, 0.44424552527467476), (5, 0.3244870206138555), (6, 0.44424552527467476), (7, 0.3244870206138555)]\n",
        "[(2, 0.5710059809418182), (5, 0.4170757362022777), (7, 0.4170757362022777), (8, 0.5710059809418182)]\n",
        "[(1, 0.49182558987264147), (5, 0.7184811607083769), (8, 0.49182558987264147)]\n",
        "[(3, 0.6282580468670046), (6, 0.6282580468670046), (7, 0.45889394536615247)]\n",
        "[(9, 1.0)]\n",
        "[(9, 0.7071067811865475), (10, 0.7071067811865475)]\n",
        "[(9, 0.5080429008916749), (10, 0.5080429008916749), (11, 0.695546419520037)]\n",
        "[(4, 0.6282580468670046), (10, 0.45889394536615247), (11, 0.6282580468670046)]\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lsi = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=2) # initialize an LSI transformation\n",
      "corpus_lsi = lsi[corpus_tfidf] # create a double wrapper over the original corpus: bow->tfidf->fold-in-lsi\n",
      "lsi.print_topics(2) # For the toy corpus above we used only 2 latent dimensions, but on real corpora, target dimensionality of 200\u2013500 is recommended as a \u201cgolden standard\u201d"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 27,
       "text": [
        "[u'0.703*\"trees\" + 0.538*\"graph\" + 0.402*\"minors\" + 0.187*\"survey\" + 0.061*\"system\" + 0.060*\"time\" + 0.060*\"response\" + 0.058*\"user\" + 0.049*\"computer\" + 0.035*\"interface\"',\n",
        " u'0.460*\"system\" + 0.373*\"user\" + 0.332*\"eps\" + 0.328*\"interface\" + 0.320*\"time\" + 0.320*\"response\" + 0.293*\"computer\" + 0.280*\"human\" + 0.171*\"survey\" + -0.161*\"trees\"']"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for doc in corpus_lsi:\n",
      "    print(doc)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(0, 0.066007833960906467), (1, 0.52007033063618457)]\n",
        "[(0, 0.19667592859142904), (1, 0.76095631677000419)]\n",
        "[(0, 0.089926399724468351), (1, 0.72418606267525043)]\n",
        "[(0, 0.075858476521785317), (1, 0.63205515860034234)]\n",
        "[(0, 0.10150299184980416), (1, 0.5737308483002953)]\n",
        "[(0, 0.70321089393783021), (1, -0.16115180214026206)]\n",
        "[(0, 0.87747876731198216), (1, -0.1675890686465992)]\n",
        "[(0, 0.90986246868185705), (1, -0.14086553628719539)]\n",
        "[(0, 0.61658253505692839), (1, 0.053929075663890408)]\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lsi.save('/tmp/model.lsi') # same for tfidf, lda, ...\n",
      "lsi = models.LsiModel.load('/tmp/model.lsi')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = models.LdaModel(corpus, id2word=dictionary, num_topics=100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}